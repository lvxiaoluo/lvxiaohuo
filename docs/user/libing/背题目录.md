一、**kafka**

1、 **Topic 和 Partition**

Partitions 分区：上面 Topic 的描述中，把 Topic 看做了一个队列，实际上，一个 Topic 是由多个队列组成的，被称为【Partition（分区）】。这样可以便于 Topic 的扩展。

2、**Partition的分布**

Topic A 的 Partition #1 有3份，分布在各个 Node 上。这样可以增加 Kafka 的可靠性和系统弹性。3个 Partition #1 中，ZooKeeper 会指定一个 Leader，负责接收生产者发来的消息。

其他2个 Partition #1 会作为 Follower，Leader 接收到的消息会复制给 Follower。

3、**保持高可用**

1）备份机制

Kafka允许同一个Partition存在多个消息副本，每个Partition的副本通常由1个Leader及0个以上的Follower组成，生产者将消息直接发往对应Partition的Leader，Follower会周期地向Leader发送同步请求

同一Partition的Replica不应存储在同一个Broker上

2)ISR机制(即 in-sync Replica)**

保持同步不是指与Leader数据保持完全一致，只需在`replica.lag.time.max.ms`时间内与Leader保持有效连接

3）Unclean领导者选举

当Kafka中`unclean.leader.election.enable`配置为true(默认值为false)且ISR中所有副本均宕机的情况下，才允许ISR外的副本被选为Leader，此时会丢失部分已应答的数据

4）ack机制

5）故障恢复机制

首先需要在集群所有Broker中选出一个Controller，负责各Partition的Leader选举以及Replica的重新分配

集群中的Controller也会出现故障，因此Kafka让所有Broker都在ZooKeeper的Controller节点上注册一个Watcher

Controller发生故障时对应的Controller临时节点会自动删除，此时注册在其上的Watcher会被触发，所有活着的Broker都会去竞选成为新的Controller(即创建新的Controller节点，由ZooKeeper保证只会有一个创建成功)

4、**kafka为什么要设计分区？**

解决伸缩性的问题，防止单台 Broker 机器都无法容纳

5、**两种消息引擎模型**

如果所有实例都属于同一个 Group， 那么它实现的就是点对点模型；如果所有实例分别属于不 同的 Group，那么它实现的就是发布 / 订阅模型。

6、**一个 Group 下该有多少个 Consumer 实例呢**

 Consumer 实例的数量应该等于该 Group 订阅主题的分区总数，也就是一个consumer示例只对应一个分区，这样的情况最合理

7、**Rebalance**

Rebalance 本质上是一种协议，规定了一个 Consumer Group 下的所有 Consumer 如何达成一致，来分配订阅 Topic 的每个分区。比如某个 Group 下有 20 个 Consumer 实例，它订阅了一个具有 100 个分区的 Topic。正常情况下，Kafka 平均会为每个 Consumer 分配 5 个分区。这个分配的过程就叫 Rebalance



二、**mysql**

1、事务的隔离性是通过锁实现，而事务的原子性、一致性和持久性是通过事务的日志实现的。 MySQL 在可重复读级别解决了幻读问题，通过行锁和间隙锁的组合 Next-Key 锁实现的。行锁与表锁是基于索引来说的（且索引要生效），不带索引 （表锁）要全表扫描。

2、**事务隔离的实现原理**

1）读未提交

2）读已提交,每次执行语句的时候都重新生成一次快照

3）可重复读，MVCC (多版本并发控制) 的方式，版本的字段，记为 `row trx_id`，字段值同事务 ID 记为 `transaction id`，它在事务开始的时候向事务系统申请，按时间先后顺序递增。可重复读是在事务开始的时候生成一个当前事务全局性的快照,**读提交**和**可重复读**两者主要的区别就是在**快照的创建上**，**可重复读**仅在事务开始时创建一次（**可重复读**沿用第一次生成的readview），而**读已提交**每次执行语句的时候都要重新创建一次

4）串行化，读的时候加共享锁，写的时候加排它锁



3、**解决幻读**用的也是锁，叫做**间隙锁**，**MySQL 把行锁和间隙锁合并在一起，解决了并发写和幻读的问题**，这个锁叫做 **Next-Key锁**。在数据库中会为索引维护一套B+树，用来快速定位行记录。B+索引树是有序的，所以会把这张表的索引分割成几个区间。**上面是有索引的情况**，如果 age 不是索引列，那么数据库会为整个表加上间隙锁。所以，如果是没有索引的话，不管 age 是否大于等于30，都要等待事务A提交才可以成功插入。

4、**日志区别**

1)**binlog** ：binlog是mysql的逻辑日志，可以简单理解为记录的就是sql语句。binlog是通过追加的方式进行写入的。binlog的主要使用场景有两个，分别是主从复制和数据恢复。

binlog的日志格式,**STATMENT \ ROW \ MIXED**

2)**redolog**



3)**undolog**

4、**MVCC**每行增加两个隐藏字段来实现MVCC，一个用来记录数据行的创建时间，另一个用来记录行的过期时间（删除时间）。在实际操作中，存储的并不是时间，而是事务的版本号，每开启一个新事务，事务的版本号就会递增。对select \insert\update\delete有不同操作.

5、**mysql在rr隔离级别下一定程度上解决了幻读问题**。 由于innodb引擎下存在当前读和快照读的概念。

在当前读的情况下，mysql通过配置可以采用记录锁(Record Lock)+间隙锁(Gap Lock)，让其他插入或删除事务死锁，达到解决幻读问题。

在快照读的情况下，mysql如果不更新插入记录，那么由于是读取的旧版本记录，对于其他事务插入数据不可见，从而达到了解决幻读问题。但是如果当前事务更新记录(包括不可见的)，会去读取最新版本内容，从而看到了其他事务插入的数据，产生幻读。

6、**如何处理死锁**

1）等待，直到超时（innodb_lock_wait_timeout=50s） 2）发起死锁检测，发现死锁后，主动回滚死锁中的某一个事务，让其他事务继续进行。

7、**如何避免死锁**

1）在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，而不应该先申请共享锁，更新时再申请排他锁 2）如果事务需要修改或锁定多个表，则应在每个事务中以相同的顺序使用加锁语句。

8、**优化锁？**

1）选择合适的事务大小，小的事务发生锁冲突的几率也更小 2）可以适当降低隔离级别 3）创建索引，并尽量使用索引访问数据库，使锁更精确，从而减少锁冲突 4）除非必须，查询时不要显示加锁。MySQL的MVCC可以实现事务中的查询不用加锁，优化事务性能 5）不同的程序访问一组表时，尽量约定以相同的顺序访问各表，对一个表而言，尽可能以固定的顺序存取表中的行，这样可以大大减少死锁的机会。

9、**不声明主键创建表的危害？**

1）不声明主键的情况下，当主键id达到2^32-1时，归0，重新计算，相同的主键直接覆盖记录。声明了主键的情况下，当主键达到最大值时，报错主键冲突。（int改为bigint）

2）行锁锁的是全表。

3）每行记录附加一个隐藏字段叫做_rowid（6个byte），相较于我们自己声明的4个byte，造成了资源的浪费。

三、**redis**

1、**redis多线程**

Redis 4.0引入`Lazy Free`线程，解决了诸如大键删除导致服务器阻塞问题，

在6.0版本引入了`I/O Thread`线程，正式实现了多线程，多线程部分，利用多核来分担I/O读写负荷，在`事件处理线程`每次获取到可读事件时，会将所有就绪的读事件分配给`I/O线程`，并进行等待，在所有`I/O线程`完成读操作后，`事件处理线程`开始执行任务处理，在处理结束后，同样将写事件分配给`I/O线程`，等待所有`I/O`线程完成写操作。

但相较于Tair，并不太优雅，而且性能提升上并不多，压测看，多线程版本性能是单线程版本的2倍，Tair多线程版本则是单线程版本的3倍。
